{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import division\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from sklearn.datasets import load_files\n",
    "import numpy as np\n",
    "import random\n",
    "import scipy\n",
    "from scipy.sparse import csr_matrix\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk import WordNetLemmatizer\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import f1_score\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['target_names', 'data', 'target', 'DESCR', 'filenames']\n",
      "['target_names', 'data', 'target', 'DESCR', 'filenames']\n"
     ]
    }
   ],
   "source": [
    "train = load_files(os.path.join(os.getcwd(), '..', 'data', 'raw', '20news-bydate', '20news-bydate-train'), encoding = 'utf-8', decode_error= 'replace')\n",
    "print train.keys()\n",
    "test = load_files(os.path.join(os.getcwd(), '..', 'data', 'raw', '20news-bydate', '20news-bydate-test'), encoding = 'utf-8', decode_error= 'replace')\n",
    "print train.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stopwords = set(stopwords.words('english'))\n",
    "stemmer = PorterStemmer()\n",
    "wnl = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    tokenizer = RegexpTokenizer(r'[a-z]+')\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    filtered_words = [w for w in tokens if not w in stopwords]\n",
    "    lemmed_words = [wnl.lemmatize(w) for w in filtered_words]\n",
    "    #stemmed_words = [stemmer.stem(w) for w in filtered_words]\n",
    "    return \" \".join(lemmed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11314/11314 [00:09<00:00, 1210.72it/s]\n",
      "100%|██████████| 7532/7532 [00:05<00:00, 1368.55it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(train['data']))):\n",
    "    train['data'][i] = preprocess(train['data'][i])\n",
    "for i in tqdm(range(len(test['data']))):\n",
    "    test['data'][i] = preprocess(test['data'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vect = CountVectorizer()\n",
    "tfidf = TfidfTransformer()\n",
    "train_vect = vect.fit_transform(train['data'])\n",
    "test_vect = vect.transform(test['data'])\n",
    "train_tfidf = tfidf.fit_transform(train_vect)\n",
    "test_tfidf = tfidf.transform(test_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_target = train['target']\n",
    "test_target = test['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84427513752902894"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LinearSVC()\n",
    "clf.fit(train_tfidf, train_target)\n",
    "predicted = clf.predict(test_tfidf)\n",
    "baseline = f1_score(test_target, predicted, average= 'macro')\n",
    "baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def delete_rows_csr(mat, indices):\n",
    "    if not isinstance(mat, scipy.sparse.csr_matrix):\n",
    "        raise ValueError(\"works only for CSR format -- use .tocsr() first\")\n",
    "    indices = list(indices)\n",
    "    mask = np.ones(mat.shape[0], dtype=bool)\n",
    "    mask[indices] = False\n",
    "    return mat[mask]\n",
    "def delete_columns_csr(M, idx_to_drop):\n",
    "    keep = np.logical_not(np.in1d(np.r_[:M.shape[1]], idx_to_drop))\n",
    "    return M[:, np.where(keep)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 184 ms, sys: 40 ms, total: 224 ms\n",
      "Wall time: 1min 5s\n",
      "4178 0.845163696052 0.000888558522885\n",
      "5013 0.84482129586 0.000546158331172\n",
      "5848 0.844727720845 0.000452583316319\n",
      "12532 0.844416957986 0.000141820456874\n",
      "16709 0.844406965122 0.000131827592775\n",
      "15873 0.844406965122 0.000131827592775\n",
      "17544 0.844406965122 0.000131827592775\n",
      "18379 0.844399687452 0.000124549922601\n",
      "3342 0.844354332317 7.91947874914e-05\n",
      "6684 0.844310686665 3.55491360136e-05\n"
     ]
    }
   ],
   "source": [
    "feat_weights = np.fabs(clf.coef_)\n",
    "sorted_feat_weights = np.fliplr(np.argsort(feat_weights))\n",
    "\n",
    "#cut_off from 1 to 82706\n",
    "def experiment(cut_off):\n",
    "    selected_words = []\n",
    "    for row in sorted_feat_weights:\n",
    "        selected_words = np.append(selected_words, row[:cut_off])\n",
    "    #print len(selected_words)\n",
    "    selected_words = np.unique(selected_words)\n",
    "    #print len(selected_words)\n",
    "    all_range = range(sorted_feat_weights.shape[1])\n",
    "\n",
    "    mask = np.delete(all_range, selected_words)\n",
    "\n",
    "    new_train_tfidf = delete_columns_csr(csr_matrix(train_tfidf), mask)\n",
    "    new_test_tfidf = delete_columns_csr(csr_matrix(test_tfidf), mask)\n",
    "\n",
    "    clf = LinearSVC()\n",
    "    clf.fit(new_train_tfidf, train_target)\n",
    "    predicted = clf.predict(new_test_tfidf)\n",
    "    return f1_score(test_target, predicted, average= 'macro')\n",
    "\n",
    "#inputs = range(1, 82706)\n",
    "inputs = np.linspace(1, sorted_feat_weights.shape[1], num=100)\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "%time results = Parallel(n_jobs=4)(delayed(experiment)(int(i)) for i in inputs)\n",
    "sorted_results = np.flipud(np.sort(results))\n",
    "sorted_permutation = np.flipud(np.argsort(results))\n",
    "nums = inputs.astype(int)\n",
    "for i in range(10):\n",
    "    print nums[sorted_permutation[i]], sorted_results[i], sorted_results[i] - baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/dist-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 164 ms, sys: 48 ms, total: 212 ms\n",
      "Wall time: 51.3 s\n",
      "25898 0.845403251549 0.00112811401997\n",
      "25063 0.84535744091 0.00108230338104\n",
      "30075 0.845127006065 0.000851868536233\n",
      "28404 0.845114341534 0.000839204004848\n",
      "38429 0.845078515479 0.000803377949597\n",
      "52631 0.845057878286 0.000782740756973\n",
      "53466 0.84504366304 0.000768525510919\n",
      "40100 0.845013053704 0.000737916175461\n",
      "46783 0.845005138938 0.000730001409358\n",
      "49289 0.844910629664 0.000635492134663\n"
     ]
    }
   ],
   "source": [
    "chi2_stat, pval_stat = chi2(train_tfidf, train_target)\n",
    "\n",
    "sorted_chi2_stat = np.flipud(np.argsort(chi2_stat))\n",
    "\n",
    "#cut_off from 1 to 82706\n",
    "def experiment(cut_off):\n",
    "    selected_words = []\n",
    "    selected_words = sorted_chi2_stat[:cut_off]\n",
    "    #print len(selected_words)\n",
    "    all_range = range(len(sorted_chi2_stat))\n",
    "\n",
    "    mask = np.delete(all_range, selected_words)\n",
    "\n",
    "    new_train_tfidf = delete_columns_csr(csr_matrix(train_tfidf), mask)\n",
    "    new_test_tfidf = delete_columns_csr(csr_matrix(test_tfidf), mask)\n",
    "\n",
    "    clf = LinearSVC()\n",
    "    clf.fit(new_train_tfidf, train_target)\n",
    "    predicted = clf.predict(new_test_tfidf)\n",
    "    return f1_score(test_target, predicted, average= 'macro')\n",
    "\n",
    "#inputs = range(1, 82706)\n",
    "inputs = np.linspace(1, len(sorted_chi2_stat), num=100)\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "%time results = Parallel(n_jobs=4)(delayed(experiment)(int(i)) for i in inputs)\n",
    "sorted_results = np.flipud(np.sort(results))\n",
    "sorted_permutation = np.flipud(np.argsort(results))\n",
    "nums = inputs.astype(int)\n",
    "for i in range(10):\n",
    "    print nums[sorted_permutation[i]], sorted_results[i], sorted_results[i] - baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/dist-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 160 ms, sys: 60 ms, total: 220 ms\n",
      "Wall time: 55.6 s\n",
      "45948 0.845233292849 0.000958155320402\n",
      "27569 0.845215900352 0.000940762823013\n",
      "49289 0.845203424001 0.00092828647192\n",
      "50125 0.845203096661 0.000927959132212\n",
      "48454 0.845201588551 0.000926451022393\n",
      "47619 0.845201261212 0.000926123682684\n",
      "30075 0.845106480352 0.000831342823362\n",
      "45112 0.845097201104 0.000822063575152\n",
      "46783 0.845073315677 0.000798178147991\n",
      "35923 0.845071104059 0.00079596652998\n"
     ]
    }
   ],
   "source": [
    "vth = VarianceThreshold()\n",
    "vth.fit(train_tfidf)\n",
    "vths = vth.variances_\n",
    "\n",
    "sorted_vths = np.flipud(np.argsort(vths))\n",
    "\n",
    "#cut_off from 1 to 82706\n",
    "def experiment(cut_off):\n",
    "    selected_words = []\n",
    "    selected_words = sorted_vths[:cut_off]\n",
    "    #print len(selected_words)\n",
    "    all_range = range(len(sorted_vths))\n",
    "\n",
    "    mask = np.delete(all_range, selected_words)\n",
    "\n",
    "    new_train_tfidf = delete_columns_csr(csr_matrix(train_tfidf), mask)\n",
    "    new_test_tfidf = delete_columns_csr(csr_matrix(test_tfidf), mask)\n",
    "\n",
    "    clf = LinearSVC()\n",
    "    clf.fit(new_train_tfidf, train_target)\n",
    "    predicted = clf.predict(new_test_tfidf)\n",
    "    return f1_score(test_target, predicted, average= 'macro')\n",
    "\n",
    "#inputs = range(1, 82706)\n",
    "inputs = np.linspace(1, len(sorted_vths), num=100)\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "%time results = Parallel(n_jobs=4)(delayed(experiment)(int(i)) for i in inputs)\n",
    "sorted_results = np.flipud(np.sort(results))\n",
    "sorted_permutation = np.flipud(np.argsort(results))\n",
    "nums = inputs.astype(int)\n",
    "for i in range(10):\n",
    "    print nums[sorted_permutation[i]], sorted_results[i], sorted_results[i] - baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vth = VarianceThreshold()\n",
    "vth.fit(train_tfidf)\n",
    "vths = vth.variances_\n",
    "#importances array vths\n",
    "def experiment(importance_array):\n",
    "    sorted_vths = np.flipud(np.argsort(vths))\n",
    "\n",
    "    def get_scores(cut_off):\n",
    "        selected_words = []\n",
    "        selected_words = sorted_vths[:cut_off]\n",
    "        \n",
    "        all_range = range(len(sorted_vths))\n",
    "\n",
    "        mask = np.delete(all_range, selected_words)\n",
    "\n",
    "        new_train_tfidf = delete_columns_csr(csr_matrix(train_tfidf), mask)\n",
    "        new_test_tfidf = delete_columns_csr(csr_matrix(test_tfidf), mask)\n",
    "\n",
    "        clf = LinearSVC()\n",
    "        clf.fit(new_train_tfidf, train_target)\n",
    "        predicted = clf.predict(new_test_tfidf)\n",
    "        return np.mean(cross_val_score(LinearSVC(), new_train_tfidf, train_target, scoring='f1_macro')), f1_score(test_target, predicted, average= 'macro')\n",
    "\n",
    "    inputs = np.linspace(1, len(sorted_vths), num=100)\n",
    "    num_cores = multiprocessing.cpu_count()\n",
    "    %time results = Parallel(n_jobs=4)(delayed(experiment)(int(i)) for i in inputs)\n",
    "    sorted_results = np.flipud(np.sort(results))\n",
    "    sorted_permutation = np.flipud(np.argsort(results))\n",
    "    nums = inputs.astype(int)\n",
    "    for i in range(10):\n",
    "        print nums[sorted_permutation[i]], sorted_results[i], sorted_results[i] - baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#cut_off from 1 to 82706\n",
    "def experiment2(cut_off):\n",
    "    selected_words = []\n",
    "    selected_words = sorted_vths[:cut_off]\n",
    "    #print len(selected_words)\n",
    "    all_range = range(len(sorted_vths))\n",
    "\n",
    "    mask = np.delete(all_range, selected_words)\n",
    "\n",
    "    new_train_tfidf = delete_columns_csr(csr_matrix(train_tfidf), mask)\n",
    "    new_test_tfidf = delete_columns_csr(csr_matrix(test_tfidf), mask)\n",
    "\n",
    "    clf = LinearSVC()\n",
    "    clf.fit(new_train_tfidf, train_target)\n",
    "    predicted = clf.predict(new_test_tfidf)\n",
    "    #predicted2 = clf.predict(new_train_tfidf)\n",
    "    #print f1_score(test_target, predicted, average= 'macro'), f1_score(train_target, predicted2, average= 'macro')\n",
    "    print f1_score(test_target, predicted, average= 'macro')\n",
    "    print np.mean(cross_val_score(LinearSVC(), new_train_tfidf, train_target, scoring='f1_macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.845097201104\n",
      "0.911937191379\n",
      "0.84360180173\n",
      "0.910835246139\n"
     ]
    }
   ],
   "source": [
    "experiment2(45000)\n",
    "experiment2(20000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
